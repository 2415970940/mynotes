Spark Streaming(1) 简介
1.大数据实时计算介绍
1.Spark Streaming 其实就是一种spark 提供的对于大数据进行实时计算的一种框架，他的底层其实也是之前提到的spark core 基本的计算模型，还是基于内存的大数据实时计算模型。而且他的底层的组件或者叫做概念其实最核心的还是RDD.
只不过，针对于实时计算的特点，在RDD 之上进行了一次封装，叫做DStream .其实 学过spark sql 之后，你理解这种封装就更容易了。之前学习spark sql 是不是也是发现它针对于数据查询这种应用提供了一种基于RDD 至少的全新概念，
DataSet 但是其底层还是基于RDD 的。所以RDD 是整个Spark 技术生态中的核心。要学好Spark 在交互式查询，实时计算上的应用技术和框架，首先必须学好spark 核心编程，也就是spark core. 
2.实时数据现在是大数据领域里面的一种非常热门的场景和应用，而且技术相当的有难度，应该是比spark core 以及mapReduce 实现的离线处理，以及Hive 和spark sql 可以实现的大数据的交互式查询，比这两种场景都要难的多。 
3.现在企业中，以及现在这个世界中，主要的实时数据产生的源头，有哪些呢，最基本的各大网站的实时用户行为日志，还有一些比如说金融系统，实时的舆情监控系统，接收的全部都是实时的金融交易数据，实时的社会上的一些舆论数据如微博等等。 
4.一般实时数据都是发送到消息中间件上面去的如kafka。比如网站上的一次点击javascript 脚本就会发送一次ajax 请求到后台的kafka 中去。其实就是作为实时大数据的一种缓冲。否则大数据系统直接处理实时数据，恐怕撑不住。 
5.我们编写的大数据处理程序，通常都会去消息中间件实时拉取数据，实时拉取到了数据之后，其实我们自己编写的分布式程序，就会用分布式的方式，来并行处理，实时的大数据，每个节点可能就处理一部分的实时的数据。这样多个节点同时并行的处理，就可以增强我们的大数据实时计算的能力提高处理速度。 
6.我们其实要做的其实就是开发这些分布式大数据应用/系统。通常来说我们来说我们都不会自己手动开发基础的分布式实时计算平台/框架，而是使用现成的，优秀的，开源的，框架/平台。比如spark streaming stom. 他们其实就是一种分布式实时计算平台，
其进程，可以部署多个节点，从而进行分布式大数据的分布式实时处理。而我们自己编写的基于某种平台的大数据平台的实时计算程序，就会以并行的方式，运行在这些平台之上。

1.Spark Stream 简介
Spark Stream是spark core Api 的一种扩展，他可以用于大规模，高吞吐量，容错的实时数据流处理。它支持从多种数据源读取数据，比如kafka ,flume,ZeroMQ 等等并且能够使用类似高阶函数的复杂算法来进行数据处理，比如map reduce,join 等等。处理后的数据可以被保存到文件系统 , 数据库等等

2.spark Streaming 基本工作原理
Spark Streaming 内部的基本工作原理如下：接收实时输入数据流，然后将数据拆分成多个batch 比如每收集一秒的数据封装为一个batch ，然后将每个batch 交给spark 的计算我们引擎进行处理，最后会产生出一个结果数据流，其中的数据，也是由一个一个的batch 所有组成。 


3.DStream（一）
Spark Streaming 提供了一种高级抽象，叫做DStream，英文全称为 
Discretized Stream ,中文翻译为“离散流” 它代表了一个持续不断的数据流。DStream 可以通过输入数据源来创建，不如kafka flume kinesis; 
也可以通过对其他DStream 应用高阶函数来创建，比如map ,reduce,join等等DStream的内部其实是一系列持续不断的RDD RDD 是spark core 的核心抽象，即不可变的分布式的数据集，DStream 中每个RDD 都包含了一段时间内的数据集合。 


4.DStream（二）
对于Dstream 应用的算子，比如map 其实在底层会被翻译成对DStream这种每个RDD的操作，比如对于个DStream执行一个map操作，会产生一个新的DStream，但是在底层，其实其原理为对输入DStream中每个的RDD 都应用一遍map 操作，然后生成新的RDD 即作为新的DStream中那个时间段的一个RDD 底层的RDD 的transformation操作，其实还是由sparkcore 的计算引擎来实现的，spark streaming 对于spark core 机型了一层封装，隐藏可细节，然后对开发人员提供了方便易用的高层次api 


1.storm简介
Storm是一个分布式的，可靠的，容错的数据流处理系统。Storm集群的输入流由一个被称作spout的组件管理，spout把数据传递给bolt， bolt要么把数据保存到某种存储器，要么把数据传递给其它的bolt。一个Storm集群就是在一连串的bolt之间转换spout传过来的数据。

2.对比
用一张图来表示 


3. Spark Streaming与Storm的优劣分析
事实上，Spark Streaming绝对谈不上比Storm优秀。这两个框架在实时计算领域中，都很优秀，只是擅长的细分场景并不相同。

Spark Streaming仅仅在吞吐量上比Storm要优秀，而吞吐量这一点，也是历来挺Spark Streaming，贬Storm的人着重强调的。但是问题是，是不是在所有的实时计算场景下，都那么注重吞吐量？不尽然。因此，通过吞吐量说Spark Streaming强于Storm，不靠谱。

事实上，Storm在实时延迟度上，比Spark Streaming就好多了，前者是纯实时，后者是准实时。而且，Storm的事务机制、健壮性 / 容错性、动态调整并行度等特性，都要比Spark Streaming更加优秀。

Spark Streaming，有一点是Storm绝对比不上的，就是：它位于Spark生态技术栈中，因此Spark Streaming可以和Spark Core、Spark SQL无缝整合，也就意味着，我们可以对实时处理出来的中间数据，立即在程序中无缝进行延迟批处理、交互式查询等操作。这个特点大大增强了Spark Streaming的优势和功能。

4. Spark Streaming与Storm的应用场景
4.1对于Storm来说： 
1、建议在那种需要纯实时，不能忍受1秒以上延迟的场景下使用，比如实时金融系统，要求纯实时进行金融交易和分析 
2、此外，如果对于实时计算的功能中，要求可靠的事务机制和可靠性机制，即数据的处理完全精准，一条也不能多，一条也不能少，也可以考虑使用Storm 
3、如果还需要针对高峰低峰时间段，动态调整实时计算程序的并行度，以最大限度利用集群资源（通常是在小型公司，集群资源紧张的情况），也可以考虑用Storm

4、如果一个大数据应用系统，它就是纯粹的实时计算，不需要在中间执行SQL交互式查询、复杂的transformation算子等，那么用Storm是比较好的选择

4.2对于Spark Streaming来说：

1、如果对上述适用于Storm的三点，一条都不满足的实时场景，即，不要求纯实时，不要求强大可靠的事务机制，不要求动态调整并行度，那么可以考虑使用Spark Streaming 
2、考虑使用Spark Streaming最主要的一个因素，应该是针对整个项目进行宏观的考虑，即，如果一个项目除了实时计算之外，还包括了离线批处理、交互式查询等业务功能，而且实时计算中，可能还会牵扯到高延迟批处理、交互式查询等功能，那么就应该首选Spark生态，用Spark Core开发离线批处理，用Spark SQL开发交互式查询，用Spark Streaming开发实时计算，三者可以无缝整合，给系统提供非常高的可扩展性
